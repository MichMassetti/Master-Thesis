%% LaTeX2e class for student theses
%% sections/evaluation.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute of Information Security and Dependability (KASTEL)
%%
%% Template by
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Adaption by
%% Annika Vielsack
%% vielsack@kit.edu
%%
%% Version 1.0, 2021-07-03

\chapter{Evaluation}
\label{ch:Evaluation}
This chapter covers the outcomes of the tools, basically, what we obtained from our experiments. 

Firstly, we describe the individual outcomes per tool, providing details about the running of those, problem that we faced off during the installation and usage. 
Then, we compare the tools based on these aspects, making subgroups due to their speifications.



%-----> TIPS: -practical experience about running, modifies of the  code, problem with solidity version 
\section{Individual Outcomes per Tool}

We describe the eventual problems during the installation and running phase, moreover, we show per each tool the outcomes of each analysis having as objective a specific attack. 
Per each tool, a table expresses the number of written lines of code considering the specifications, we did not count the ones which were copied from the target smart contracts. 
The second field deals with the execution time of the tool and the last one specifies if the vulnerability was effectively detected.

The code of the exploits was modified to keep the vulnerable aspects, reproducing their logic, but the irrelevant parts were discarded.

We kept the same simplified version of the smart contracts for all the tools.

\paragraph{Manticore} The provided guide on Github (\cite{ManticoreGitHub}) gives a detailed guide for Manticore installation. 
Since it is written in python, we used a virtual environment and we counted around nine libraries for dependences. The installation involved basically one command, since it was managed by "pip", python packet manager.
We adopted its default running mode for the attacks involving reentrancy and "Manticore-verifier" running mode for the others. 

The table \autoref*{tab:ManticoreTable} shows the outcames of the analyses per attack; the symbol "--" means that in that case we did not use the 
"Manticore-verifier" running mode, but the default one, which it does not need a specification file.

\begin{center}
\begin{table*}
    \caption{Manticore results}
        \label{tab:ManticoreTable}
        \begin{tabular}{cccc}
        \toprule
            Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud\\
            \midrule
            Aku & 6 & 235  & Not Found \\ 
            Cover & 5 & 245 & Not Found \\ 
            BZX  & 4 & 228 & Found \\ 
            Spartan & 3 & 239 & Found \\ 
            Uranium  & 3 & 250 & Not Found \\ 
            XSURGE & -- & 208 & Found \\ 
            BurgerSwap  &  -- & 205 & Found\\ 
            DirtyDogs & -- & 203 & Found \\
        \bottomrule
    \end{tabular}
\end{table*}
\end{center}

\paragraph{SmarTest} SmarTest is built on top of VeriSmart tool, so it can be seen like a plug in of these one. Indeed, we run SmarTest as an option of VeriSmart, 
as the Github guide explains (\cite{SmarTestGitHub}). The tool is built with OCalm, a program language, so we used for the installation "opam", which is a source-based package manager for it.
An important dependency is Z3, its satisfiability modulo theories (SMT) solver. Solc, the compiler for solidity, is required.

Since it has no the dector for reentrancy, as the table \autoref{tab:SmarTestTable} shows, the attacks involving it were discarded. We adopted just the "assertion" running mode, for obtating valuable results. 
We fixed a running time threshold of 320 seconds.

\begin{center}
    \begin{table*}
        \caption{SmarTest results}
            \label{tab:SmarTestTable}
            \begin{tabular}{cccl}
            \toprule
                Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud\\
                \midrule
                Aku & 3 & 320 & Found \\ 
                Cover & 2 & 310& Not Found\\ 
                BZX  & 4 & 320 & Found\\ 
                Spartan & 2 & 320& Not Found\\ 
                Uranium  & 4 & 320 & Found \\ 
                XSURGE &  -- & -- & Not Found \\  
                BurgerSwap &  -- & -- & Not Found\\ 
                DirtyDogs &  -- & -- & Not Found \\
            \bottomrule
            \end{tabular}
        \end{table*}
\end{center}


\paragraph{Celestial} 
Celestial is a tool which encompasses two main steps: the translation of the target smart contract in F* and then the running of the formal verification engine. 
This is the tool that required the most amount of time for installation and usage. 
It did not cover reentrancy attacks, so those exploits were discarded, moreover, it did not cover the keywords "storage" and "memory", 
so the "Cover Protocol" exploit was discarded as well. 
During the running, we used multiple versions of F* and in some cases (as with the "Uranium" exploit) the conversion was not correct so we adjusted the F* code to let it work. 

\begin{center}
    \begin{table*}
        \caption{Celestial results}
            \label{tab:CelestialTable}
                \begin{tabular}{cccl}
                \toprule
                    Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud\\
                    \midrule
                    Aku & 22 & 4 & Found\\ 
                    Cover & --  & -- & Not Found \\ 
                    BZX & 15 & 3 & Found\\ 
                    Spartan & 29 &  5 & Found \\ 
                    Uranium & 18 &  5 & Found \\ 
                    XSURGE &  -- & -- & Not Found \\  
                    BurgerSwap &  -- & -- & Not Found\\ 
                    DirtyDogs &  -- & -- & Not Found \\
                \bottomrule
                \end{tabular}
    \end{table*}
        
\end{center}
\paragraph{Echidna}

\begin{center}
    \begin{table*}    
        \caption{Echidna results}
        \label{tab:EchidnaTable}
        \begin{tabular}{cccl}
        \toprule
            Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud\\
            \midrule
            Aku & 7 & 22 & Found\\ 
            Cover & 5 & 7 & Found\\ 
            BZX & 3 & 33 & Found \\ 
            Spartan & 3 & 17 & Found  \\ 
            Uranium & 3 & 24 & Found \\ 
            XSURGE & -- & -- & Found \\  
            BurgerSwap &  -- & -- & Found \\ 
            DirtyDogs &  -- & -- & Found \\
        \bottomrule
        \end{tabular}
    \end{table*}
\end{center}

\paragraph{Certora}

\begin{center}
    \begin{table*}
        \caption{Certora results; the time is provided by the sas application}
            \label{tab:CertoraTable}
            \begin{tabular}{cccl}
            \toprule
                Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud\\
                \midrule
                Aku & 52 & 14 & Found \\ 
                Cover & 31 & 21 & Found\\ 
                BZX & 25  & 18 & Found\\ 
                Spartan & 20  & 25 & Found\\ 
                Uranium & 42 & 27  & Found\\ 
                XSURGE &  -- & -- & Found\\  
                BurgerSwap &  -- & --& Found\\ 
                DirtyDogs &  -- & -- & Found\\
            \bottomrule
            \end{tabular}
    \end{table*}
\end{center}

\paragraph{SolcVerify}

\begin{center}
    \begin{table*}
        \caption{SolcVerify results}
                \label{tab:SolcVerifyTable}
                \begin{tabular}{cccl}
                \toprule
                    Attacks & Lines of Code & Execution Time (seconds) & Foud, Not Foud (seconds)\\
                    \midrule
                    Aku & 9 & 4 & Found \\ 
                    Cover & 13  & 5 & Found \\ 
                    BZX & 17  & 9  & Found \\ 
                    Spartan & 25 &  17 & Found \\ 
                    Uranium  &  23 & 9 & Found \\ 
                    XSURGE & 20 & 10 & Found \\  
                    BurgerSwap & 11 & 10  & Found \\ 
                    DirtyDogs &  30 &  14& Found \\
                \bottomrule
        \end{tabular}
    \end{table*}
    
\end{center}
\paragraph{Mythril}

\paragraph{Slither}



\section{General Comparison}
%% presenting the outcomes of single analyses, so description of the result 
%% this subsection contains objective data, in the next one I add even my point of view

The first step was the collection of all the data from the analyses with the vulnerable smart contracts as objective. 
In this part, we provide a technical comperison of the usage and result of the tools. 
This section is struction in paragraphes, which deal with a specific aspecs.

\paragraph{Installation} \autoref{tab:Installation} collects the info about the installation detalais per each tool. 
We tested the tools in a linux eniveronoment, specifically Ubuntu 20.04, indeed we do not assure the proper functioning on other OSs.

The running mode involves the way a tool can be run, we classify a tool with multiple running mode if its grammar effectivly change between different modes. For example echidna, it can be run in 
test mode and in assertion one, in the first case it requires functions with boolean formulas, in the second case the solidity keyword "assertion" in the code.

The external dependences embedde the exteranal elements, so we do not count the amount of libraries of the same language. All the tools require Solc, the solidity compiler. 
The tools which gave us problem with the external dependences are Celestial and SolcVerify. The first one needs F* for running and we found many difficulties for its installation and for selecting its right version, 
based on the tool and the system environment. On the other hand, the second one involves the usage of Boogie, an intermediate verification language, which requires .NET, (\cite{NET}), 
which is an open source, cross-platform for building many kinds of applications mantained by Microsoft. 
Its intallation took days for configure the compatible version with the local system and the required by the tool.

Since Certora operates in Service as a Service (SaaS) mode, it is the most compatible tool, it requires to be connect to internet.

\begin{center}
    \begin{table*}
        \caption{Installation}
        \label{tab:Installation}
        \begin{tabular}{ccccc}
        \toprule
            Tools  &  Running modes & Extenral Dependences & OS \\
            \midrule
            Manticore & 2 & 2 & Linux, OS X\\
            SmartTest & 2 & 3 & Linux, OS X, Windows \\
            Celestial & 1 & 3 & Linux, OS X\\
            Echidna & 2 & 2 & Linux, OS X, Windows\\
            Certora & 1 & -- & -- \\ 
            SolcVerify & 1 & 4  &  Linux, OS X \\
            Mythril  & 1 & 2  &  Linux, OS X \\ 
            Slither & 1 & 2 & Linux, OS X, Windows \\   
        \bottomrule
        \end{tabular}
    \end{table*}
    \end{center}

\paragraph{Outcomes} \autoref{tab:Results} has as rows the tools and as columns the real-world exploits. 
It shows which tool was able to scan the specified vulnerability involved in the attacks.  The caption states the symbol we have used for the classification:
\begin{itemize}
    \item \checkmark states that the vulnerability was scanned;
    \item \xmark means the tool was no able to detect it;
    \item -- stands for "discarded", tha attack was not considered for architectural reason of the tool.
\end{itemize}


We can state that the tools with specifications could not detect reentrancy in most of the cases. We classify that case as discarded. 
SolcVerify is the only one which could provide a result in all cases, moreover, it was the only tool which could detect correctly all the vulnerabilities we provided.

Celestial could not analyse BZX exploit, 
because it involved the keywords "storage" and "memory", which cannot be scanned by the tool. 

The tools without specifications gave warning in most cases, which can be used as a hint for scanning the vulnerabilities. 

Slither could not detect the exploits involving the logic of the program, moreover, it gives multiple warnings, which the developer took into count. 
An example is BZX, which involves the estimation time comparison based on timestamp, but for the tool, a comperison timestamp based is always classified as dangerous.

\begin{center}
    \begin{table*}   
        \caption{Analyses Outocomes per Attack:    
        \checkmark: Found vulenrablity, \xmark: Not found vulnerability, --: Discarded }
        \label{tab:Results}
        \begin{tabular}{ccccccccc}
        \toprule
        Tools  & Aku & Cover & BZX & Spartan & Uranium & XSURGE &  BurgerSwap & DirtyDogs\\
        \midrule
        Manticore & \xmark & \xmark & \checkmark & \checkmark & \xmark & \checkmark & \checkmark & \checkmark\\
        SmartTest & \checkmark &   \xmark & \checkmark  & \xmark &\checkmark  & -- & -- & --  \\
        Celestial & \checkmark & -- & \checkmark & \checkmark & \checkmark & -- & -- & --  \\
        Echidna  & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- & -- & -- \\
        Certora & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & -- & -- & -- \\ 
        SolcVerify & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark  & \checkmark \\
        Slither & \xmark &\xmark  &\xmark & \xmark & \xmark & \checkmark & \checkmark & \checkmark \\ 
        Mythril  & \xmark & \xmark & \xmark &\xmark & \xmark & \checkmark & \checkmark & \checkmark\\
        \bottomrule
        \end{tabular}
    \end{table*}
\end{center}

\begin{center}
    \begin{table*}
        \footnotesize
        \caption{Analyses Outcomes: 
        LoF: List of functions, LoU: List of unproved tests, W: Warnings}
        \label{tab:Outcomes}
        \begin{tabular}{ccccc}
        \toprule
        Tools  & Constructive output &  Avg lines of code for test & Avg time (in seconds) \\
        \midrule
            Manticore & LoF, W  & 4  &  239,5 \\
            SmartTest & LoF, W & 2,5 &  318  \\
            Celestial & LoU & 21  &  4  \\
            Echidna & LoF  & 4  & 20,5 \\
            Certora & LoF   & 34 &  21  \\ 
            SolcVerify & LoU  &  18,5 &  10  \\
            Mythril & LoF, W  & --  &  221  \\ 
            Slither& W & --  &  3,5  \\ 
        \bottomrule
        \end{tabular}
    \end{table*}
\end{center}

\paragraph{Exploits with no reentrancy}

\paragraph{Tools behavior} 







\section{Weaknesses and Strenghts}
%% What I wrote in the table 
%% I talk even about the installation and the running phase

We present the 
\begin{table*}
    \caption{Weaknesses \& Drawbacks}
    \label{tab:Weaknesses}
    \begin{tabular}{cc}
    \toprule
        Tools  &  Weaknesses \& Drawbacks \\
        \midrule
        Manticore & Reentrancy is not dectected by properties property 
        based execution, very slow \\
        SmartTest & Reentrancy is not dectected, the analyses are slow \\
        Celestial & External calls are not considered, keywords storage and 
        memory are not recognized  \\
        Echidna &  Reentrancy is not dectected, no assetion mode for solidity 8\\
        Certora & Reentrancy is not dectected, not open-sources \\ 
        SolcVerify & It just gives warning, it does not provide a list of 
        transaction for breaking the given property\\
        Mythril & Just flat contracts are allowed \\ 
        Slither & Scan is based on the grammar, great amount of false negative \\ 
    \bottomrule
    \end{tabular}
\end{table*}

\begin{table*}
    \caption{Strenghts}
        \label{tab:Strenghts}
        \begin{tabular}{cl}
        \toprule
            Tools  &  Strenghts \\
            \midrule
            Manticore & One of the mode cover the properties breaking and the scanner one covers the reentrancy\\
            SmartTest & It allows to set the specific vulenrability to look for  \\
            Celestial & Possibility to use different version of F*  \\
            Echidna &  Possibility to run in multiple modes with different grammar (tests or assertions breaking)\\
            Certora & Implements the library of Openzeppelin, SAS no installation needed \\ 
            SolcVerify & Intuitive specification language based on Annotations, it detects reentrancy\\
            Mythril & It deos not need specification, but still provide list of functions for breaking detected vulnerability  \\ 
            Slither & Easiest installation, fastest tool that we used \\ 
        \bottomrule
        \end{tabular}
    \end{table*}

\chapter{Discussion}
\label{ch:Discussionn}

This chapter deals with the discussion of the obtained results. 
We provide a comparison between the tools about their behaviour, including our point of view on user experience. 
\section{Tools with Specifications}
%% General Overview of the strategies 
%% Comperison within the strategies 
%% Personal ideas on their usage, how was the language and so on 
The considered tools cover three main strategies for security analysis: fuzzing, symbolic execution and formal verification. 

The following paragraphes deal with comparison within this subgroup we want to stess for having a deepen view of the comparison and a last sub chapter for a general overview.

\paragraph{Formal verification} 
Formal verification is a very powerful security approach, intending to prove or unproved the given specification. 
This perfectly fits with our research goals, such as the detection of bugs or vulnerabilities in our real-world cases. 

We involved three different tools, implementing this approach, for our purpose. Regarding the results, it is clear that these were executed as fast as or even faster than the other ones. 
Certora is the only one which provides a complete list of functions for breaking the rules, rather than just a warning. 
On the other hand, SolcVerify could detect the vulnerabilities involving external call functions, indeed reentrancy. A powerful aspects of this tool is its possibility to express 
loop invariants, the other ones do not allow it.
Considering the grammar for expressing the specifications, SolcVerify is the one which needs the least amount of lines of code, indeed it involves a notification language; 
I found it very intuitive and fast to write down the specifications.

Celestial architecture encompasses two steps: the translation from celestial file to f* and then its verification. The python script converts the ".cel" in f*, used for the proof or unproof.
The provided file included the smart contract's source code plus the expressed specification. These are statements placed at the beginning of a function, otherwise, it is possible to create a sort of function, 
containing boolean formula, which is called by different specifications function with different parameters, it is useful for expressing the same specification for different purpose.  I consider it the one with more limitations, regarding solidity grammar and reentrancy, 
because it could not detect the reentrancy vunlenaribilities and the Cover protocol attack, because the keywords "storage" and "memory" are rejected. 

Certora is the only tool which is not open-source, for our purpose we adopted its free version.
Its specification language is described by its developers' group as "rule-based". It differs from the other two tools under this aspect, because this way gives more elasticity to the user and defines more specific cases.
The rule is composed of some function calls and it concludes with an assertion or more. The user is allowed to test a specific case, using "require" and the possibility to set up a proper environment. 
The preconditions, in this case, are expressed using the Solidity keyword "require" in the rule.

One of its strengths is the possibility to define the specifications we want to prove, without necessarily defining all the specifics for the rest of the functions.
On the other hand,  with Celestial and SolcVerify, we provided the specifications for all the functions for letting the tools work properly. 
Those could not prove the given properties, without the specifications for all the code.

\paragraph{Different stategies, similar grammar}
We considered two tools with similar grammar but implemented different analysis approaches: Manticore and Echidna. 
In both of the cases, we provided functions containing a boolean formula, which the tools try to break. From the results, 
we noticed that Echidna run faster and it worked for all the cases, but Manticore could cover the reentrancy vulnerabilities thanks to its changing architecture.

We encountered a common aspect between the grammar definition of the specification between the two tools Echidna and SmarTest regarding their "assertion" mode. 
Both of those require the user to write assertions and then these try to verify it or return the list of 
functions for breaking the rule. From our results, it is clear Echidna could obtain higher number of positive outomces and in less time rather than SmartTest.



\section{Customized and Non-specific Analyses} 
The objectives of our analyses were smart contracts involved in real-world exploits. The attackers exploited a specific bug or lack of security in the logic of programs. 

The specifications allowed the user to express the requirements of the program. These provide a customized analysis and 
its accuracy is demanded by the developer as well. 
Our work involved smart contracts with well-known vulnerabilities, but the definition of the properties is an indispensable and complex step.
The tools without specification implement vulnerabilities detectors, which are stated in their paper. They have well-defined limitations, but strengths as well. These detect preconfigured vulnerabilities, so a warning can be run even if we expect that indeed the number of false negatives can be relevant.
An example is Slither, which for every comparison of block time stamp give a warning. These warnings 

Our results stress the impossibility of the tools without specification for the detection of specific vulnerabilities, but they could correctly detect the reentrancy cases. 
On the other hand, the ones with specifications had problems in the reentrancy detection. The limitations of some of these involve the external calls. 
SolcVerify was the only tool which could provide the possibility of reentrancy detection. Echidna, as Certora, developers teams specified the tools  can detect the reentrancy, in the case an attack is provided, 
but we think this approach can be useful for checking a possible attack rather than detection of vulnerabilities.

Manticore could bridge this gap by adopting two different running modes, so the user, knowing the limitation of each way of analyses, can combine those for obtaining a valuable result.


\section{Effective Analysis}
%% Use tools in combination
In our work, we took into consideration the selected tools individually. 

We run those per time focusing on the results of each one, and providing a comparison between those.

During an audit or a security report, a tester runs multiple of those for discovering vulnerabilities and bugs. 
A better way to fulfil this goal is using a combination of those. 
The tools without specification have, in our experience, an easier installation and usage. 
Those can detect well know vulnerabilities and cover a predefined set of those. 
Some of the tools with specifications we dealt with had some limitations regarding the external calls. For covering this limitation, 
a combination of tools would be a solution. 
As an example, we consider a tool without specification, Slither, and one with, Echidna. 
This combination has an effective result in terms of the speed of the analyses and amount of vulnerabilities covered. Slither has the role of detecting basic issues and reentrancy, on the other hand, Echidna can be used for the detection of a vulnerable implementation of the logic of the program. Since the grammar of this is similar to Manticore, an efficient idea would be to implement the test using a tool, which implements a different logic for scanning. 
Formal verification resulted powerful for scanning possible problems, but Solc-Verify and Celestial need to write down the specification for all the contracts for obtaining a consistent result. Certora, which is not open source, has the strength of having implemented libraries which are mostly used in real-world cases (as OpenZeppelin ones). A facilitating aspect of this tool is the possibility to write down the specifications on just the properties we want to check and the possibility to code those in terms of function. It allows for the definition of specific preconditions, adding conditions to the environment. 

We suggest a combination of Echidna and Certora for covering the part of bugs in the logic and possible attacks, 
plus Slither for verifying the absence of possible reentrancy. 
We selected this combination based on the facility we had during the write down of the specifications and installation of those.

